{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "set_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshyasharma14/bro-code/blob/master/public/static/data/set_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UDhsrgPIgWY"
      },
      "source": [
        "# Generic Set Predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx8UZZMtIr_-"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm-EtH82kJ9B"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation\n",
        "from keras.optimizers import gradient_descent_v2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import chain, combinations\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import model_from_json\n",
        "from google.colab import files\n",
        "import csv\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDiHdeEhIxMj"
      },
      "source": [
        "Google Authentication to access the data sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QrxyaU5rMv-"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIOs8oxHrfgr"
      },
      "source": [
        "#random number dataset\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1bRsu9oH3N5A6N7rGFPZ3pngCvwfuHw4_57V_YCHUj38/edit?usp=sharing')\n",
        "sheet = wb.worksheet('Sheet1')\n",
        "raw_data = sheet.get_all_values()\n",
        "df = pd.DataFrame(raw_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-F43d1oTsAV"
      },
      "source": [
        "Tokenizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBgrIDFJTrP8"
      },
      "source": [
        "data=[]\n",
        "for inner in raw_data:\n",
        "  tmp = []\n",
        "  for str in inner:\n",
        "    if str != '':\n",
        "      tmp.append(str)\n",
        "  data.append(tmp)\n",
        "\n",
        "tok_data = {y for x in data for y in x}\n",
        "\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(tok_data)\n",
        "\n",
        "sequences =tokenizer.texts_to_sequences(data)\n",
        "random.shuffle(sequences)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpAfHkt1JC-Y"
      },
      "source": [
        "Preparing data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFPbhfzJRVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce77654-3da7-4a55-be72-52ef70083393"
      },
      "source": [
        "FEATURE_SET_SIZE = max(list(map(max, *sequences)))+2\n",
        "FEATURE_SET_SIZE"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMD44h9AKlDf"
      },
      "source": [
        "def binarize(num):\n",
        "  dinarized_list = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "  dinarized_list[num] = 1\n",
        "  return dinarized_list;\n",
        "\n",
        "def subset_list (num):\n",
        "    s = range(num)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(1,len(s)))\n",
        "\n",
        "def prepare_data(lst):\n",
        "  result = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "  for index in lst:\n",
        "    result[index] = 1\n",
        "  return result\n",
        "\n",
        "def split_list(a_list):\n",
        "    part = int(len(a_list)//3)\n",
        "    return a_list[part:], a_list[:part]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u2jWf8FNZOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1e559c-10ae-4c06-bf9d-541fcebb3020"
      },
      "source": [
        "input= []\n",
        "output=[]\n",
        "for row in sequences:\n",
        "  row_len = len(row)\n",
        "  for subset in subset_list(row_len):\n",
        "    input_sum = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "    output_sum = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "    for index in range(row_len):\n",
        "      if index in subset:\n",
        "        input_sum =  [a + b for a, b in zip(input_sum, binarize(row[index]))]\n",
        "      else:\n",
        "        output_sum =  [a + b for a, b in zip(output_sum, binarize(row[index]))]\n",
        "    input.append(input_sum)\n",
        "    output.append(output_sum)\n",
        "\n",
        "input= np.array(input)\n",
        "output = np.array(output)\n",
        "input"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiWmOCUGnY6_"
      },
      "source": [
        "input, test_input= split_list(input)\n",
        "output, test_output= split_list(output)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdAdc4LHJPtI"
      },
      "source": [
        "Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPGPEAzPA7D"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#\n",
        "model.add(Dense(FEATURE_SET_SIZE*2, activation='relu', input_dim=FEATURE_SET_SIZE))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(FEATURE_SET_SIZE*2, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(FEATURE_SET_SIZE, activation='softmax'))\n",
        "\n",
        "sgd= gradient_descent_v2.SGD(lr=0.001,decay=1e-6,momentum=0.9,nesterov=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XaaJFk6iZNV"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikh89aYmm4Xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5533bfbe-7ac0-4438-bf64-e078cf786288"
      },
      "source": [
        "model.fit(input,output,epochs=3,batch_size=50)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1253/1253 [==============================] - 2s 2ms/step - loss: 0.1562 - accuracy: 0.0589\n",
            "Epoch 2/3\n",
            "1253/1253 [==============================] - 2s 2ms/step - loss: 0.1358 - accuracy: 0.0687\n",
            "Epoch 3/3\n",
            "1253/1253 [==============================] - 2s 2ms/step - loss: 0.1292 - accuracy: 0.0733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc46c0e3d10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhXd7IhUCYlu"
      },
      "source": [
        "Testing model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UxzV4nynDNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7260f19-0cc1-431c-a60f-ccba737102e2"
      },
      "source": [
        "score= model.evaluate(test_input,test_output,batch_size=50)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "627/627 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.0673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2vQOO-3G_R6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7a9c01-c78b-4221-b414-4df3e70858e9"
      },
      "source": [
        "score"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1561989039182663, 0.07134189456701279]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEawFIXJCEpd"
      },
      "source": [
        "Time to test, with custom input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY9_7IuGKtL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2715b4a-ce76-4092-db55-c169782730ee"
      },
      "source": [
        "test_list=[\"j\"]\n",
        "test_list = tokenizer.texts_to_sequences(test_list)\n",
        "tmp_input=[]\n",
        "tmp_input.append(prepare_data(test_list))\n",
        "tmp_input.append(prepare_data(([1])))\n",
        "tmp_input= np.array(tmp_input)\n",
        "result = model.predict(tmp_input,batch_size=None,verbose=0,steps=None)\n",
        "indices = (-result[0]).argsort()[:]\n",
        "predicted_token = [x for x in indices if x not in test_list and x!= 0][:4]\n",
        "final_prediction = tokenizer.sequences_to_texts([predicted_token])\n",
        "final_prediction"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f o g k']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKojHI78bXDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "398be572-0776-4ec2-baa2-0b819291bb3e"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "files.download('model.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1ffc33e9-9b89-4c09-ad92-c2a1d640a181\", \"model.json\", 1917)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}