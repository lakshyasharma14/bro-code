{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "set_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshyasharma14/bro-code/blob/master/public/static/data/set_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UDhsrgPIgWY"
      },
      "source": [
        "# Generic Set Predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx8UZZMtIr_-"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm-EtH82kJ9B"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation\n",
        "from keras.optimizers import gradient_descent_v2,adam_v2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import chain, combinations\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import model_from_json\n",
        "\n",
        "from google.colab import files\n",
        "import csv\n",
        "import random"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDiHdeEhIxMj"
      },
      "source": [
        "Google Authentication to access the data sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QrxyaU5rMv-"
      },
      "source": [
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaQOVkPXQGP7"
      },
      "source": [
        "Get shopping cart data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIOs8oxHrfgr"
      },
      "source": [
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1bRsu9oH3N5A6N7rGFPZ3pngCvwfuHw4_57V_YCHUj38/edit?usp=sharing')\n",
        "\n",
        "#sheet = wb.worksheet('encoded_filter_criteria')\n",
        "sheet = wb.worksheet('shopping_cart')\n",
        "raw_data = sheet.get_all_values()\n",
        "df = pd.DataFrame(raw_data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-F43d1oTsAV"
      },
      "source": [
        "Tokenizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBgrIDFJTrP8"
      },
      "source": [
        "data=[]\n",
        "for inner in raw_data:\n",
        "  tmp = []\n",
        "  for str in inner:\n",
        "    if str != '':\n",
        "      tmp.append(str)\n",
        "  data.append(tmp)\n",
        "\n",
        "tok_data = {y for x in data for y in x}\n",
        "\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n',split='#')\n",
        "#tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tok_data)\n",
        "\n",
        "sequences =tokenizer.texts_to_sequences(data)\n",
        "random.shuffle(sequences)\n",
        "sequences = list(filter(None, sequences))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpAfHkt1JC-Y"
      },
      "source": [
        "Preparing data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFPbhfzJRVO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a2ed8c7d-7e7f-45cb-9f77-0464f3e620c3"
      },
      "source": [
        "FEATURE_SET_SIZE = max(list(map(max, *sequences)))+2\n",
        "FEATURE_SET_SIZE"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMD44h9AKlDf"
      },
      "source": [
        "def binarize(num):\n",
        "  dinarized_list = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "  dinarized_list[num] = 1\n",
        "  return dinarized_list;\n",
        "\n",
        "def subset_list (num):\n",
        "    s = range(num)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(1,len(s)))\n",
        "\n",
        "def prepare_data(lst):\n",
        "  result = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "  for index in lst:\n",
        "    result[index] = 1\n",
        "  return result\n",
        "\n",
        "def split_list(a_list):\n",
        "    part = int(len(a_list)//3)\n",
        "    return a_list[part:], a_list[:part]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u2jWf8FNZOf"
      },
      "source": [
        "input= []\n",
        "output=[]\n",
        "for row in sequences:\n",
        "  row_len = len(row)\n",
        "  for subset in subset_list(row_len):\n",
        "    input_sum = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "    output_sum = np.zeros(FEATURE_SET_SIZE, dtype=int)\n",
        "    for index in range(row_len):\n",
        "      if index in subset:\n",
        "        input_sum =  [a + b for a, b in zip(input_sum, binarize(row[index]))]\n",
        "      else:\n",
        "        output_sum =  [a + b for a, b in zip(output_sum, binarize(row[index]))]\n",
        "    input.append(input_sum)\n",
        "    output.append(output_sum)\n",
        "\n",
        "input= np.array(input)\n",
        "output = np.array(output)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiWmOCUGnY6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6e56af08-da11-4a8c-c1ee-f0a1d45f61c1"
      },
      "source": [
        "input, test_input= split_list(input)\n",
        "output, test_output= split_list(output)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142460"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdAdc4LHJPtI"
      },
      "source": [
        "Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPGPEAzPA7D"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(FEATURE_SET_SIZE*2, activation='relu', input_dim=FEATURE_SET_SIZE))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(FEATURE_SET_SIZE*2, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(FEATURE_SET_SIZE, activation=keras.activations.hard_sigmoid))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XaaJFk6iZNV"
      },
      "source": [
        "m = keras.metrics.SparseTopKCategoricalAccuracy(k=3)\n",
        "model.compile(loss='binary_crossentropy',optimizer=adam_v2.Adam(learning_rate=0.001), metrics=[\"binary_accuracy\"])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikh89aYmm4Xd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "faeec6fb-5879-43aa-c6df-c8fd2435ac8a"
      },
      "source": [
        "model.fit(input,output,epochs=1,batch_size=50)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2850/2850 [==============================] - 26s 9ms/step - loss: 0.1432 - binary_accuracy: 0.9818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd0c398110>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhXd7IhUCYlu"
      },
      "source": [
        "Testing model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UxzV4nynDNT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fb9b9b64-c24f-44a3-c9ae-5584991ce5d5"
      },
      "source": [
        "score= model.evaluate(test_input,test_output,batch_size=50)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1425/1425 [==============================] - 5s 4ms/step - loss: 0.1138 - binary_accuracy: 0.9829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2vQOO-3G_R6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "81fd8bcc-5a18-4062-e2fa-54e143411372"
      },
      "source": [
        "score[1]*100"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.29342365264893"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEawFIXJCEpd"
      },
      "source": [
        "Time to test, with custom input and predict top m most popular items a person can buy if he buy x set of item\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY9_7IuGKtL2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "80b81c74-20ff-448a-d3b6-e6a4c2e8c621"
      },
      "source": [
        "x=[\"soda\"]\n",
        "m=3\n",
        "test_list = tokenizer.texts_to_sequences(x)\n",
        "tmp_input=[]\n",
        "tmp_input.append(prepare_data(test_list))\n",
        "tmp_input.append(prepare_data(([1])))\n",
        "tmp_input= np.array(tmp_input)\n",
        "result = model.predict(tmp_input,batch_size=None,verbose=0,steps=None)\n",
        "indices = (-result[0]).argsort()[:]\n",
        "predicted_token = [x for x in indices if x not in test_list and x!= 0][:m]\n",
        "final_prediction = tokenizer.sequences_to_texts([predicted_token])\n",
        "final_prediction"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pastry canned beer whole milk']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "19c458c2-4442-4f71-ad3a-3928ea274c06",
        "id": "PdhBUhq0dS5T"
      },
      "source": [
        "x=[\"soda\", \"canned beer\"]\n",
        "m=3\n",
        "test_list = tokenizer.texts_to_sequences(x)\n",
        "tmp_input=[]\n",
        "tmp_input.append(prepare_data(test_list))\n",
        "tmp_input.append(prepare_data(([1])))\n",
        "tmp_input= np.array(tmp_input)\n",
        "result = model.predict(tmp_input,batch_size=None,verbose=0,steps=None)\n",
        "indices = (-result[0]).argsort()[:]\n",
        "predicted_token = [x for x in indices if x not in test_list and x!= 0][:m]\n",
        "final_prediction = tokenizer.sequences_to_texts([predicted_token])\n",
        "final_prediction"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['specialty chocolate sausage frankfurter']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model for future!"
      ],
      "metadata": {
        "id": "ZkWRbtBcWAiJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKojHI78bXDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d25abcb3-d4d4-4ddb-8c5d-9c29d126e2fa"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "files.download('model.json')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2088403d-8df4-4c60-9cc8-2ea5e1539281\", \"model.json\", 1892)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}